{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e75364a",
   "metadata": {},
   "source": [
    "Here are **detailed notes on Average Word2Vec** with clear explanation and examples üëá\n",
    "\n",
    "---\n",
    "\n",
    "# üß† **Average Word2Vec ‚Äì Full Notes with Example**\n",
    "\n",
    "## **1. Introduction**\n",
    "\n",
    "**Word2Vec** is a powerful word embedding technique that represents words as numerical vectors.\n",
    "However, in many NLP tasks, we need to represent **an entire sentence or document** as a single vector.\n",
    "\n",
    "üëâ **Average Word2Vec** is a simple and effective method to do this.\n",
    "It works by **averaging the Word2Vec vectors of all words** in the sentence/document.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Why Average Word2Vec?**\n",
    "\n",
    "* Word2Vec gives embeddings **only for individual words**.\n",
    "* Many tasks (like sentiment analysis, document classification, etc.) need **sentence-level or document-level representation**.\n",
    "* Instead of complex architectures, we can just take the **average of word embeddings** to represent the full text.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Concept**\n",
    "\n",
    "Let‚Äôs say a sentence has ( n ) words:\n",
    "[\n",
    "S = [w_1, w_2, w_3, \\ldots, w_n]\n",
    "]\n",
    "\n",
    "Each word ( w_i ) has a Word2Vec embedding ( v_i ) of dimension ( d ).\n",
    "Then the **Average Word2Vec vector** of the sentence is:\n",
    "\n",
    "[\n",
    "V_{avg} = \\frac{1}{n} \\sum_{i=1}^{n} v_i\n",
    "]\n",
    "\n",
    "This ( V_{avg} ) is now the **sentence embedding**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Example**\n",
    "\n",
    "Let‚Äôs take a simple example:\n",
    "\n",
    "**Sentence:**\n",
    "\n",
    "> ‚ÄúI love natural language processing‚Äù\n",
    "\n",
    "### Step 1Ô∏è‚É£: Get Word2Vec vectors\n",
    "\n",
    "Suppose Word2Vec gives:\n",
    "\n",
    "| Word       | Embedding (3 dimensions for simplicity) |\n",
    "| ---------- | --------------------------------------- |\n",
    "| I          | [0.2, 0.1, 0.3]                         |\n",
    "| love       | [0.8, 0.6, 0.7]                         |\n",
    "| natural    | [0.9, 0.4, 0.5]                         |\n",
    "| language   | [0.7, 0.5, 0.6]                         |\n",
    "| processing | [0.6, 0.9, 0.8]                         |\n",
    "\n",
    "### Step 2Ô∏è‚É£: Compute Average\n",
    "\n",
    "[\n",
    "V_{avg} = \\frac{( [0.2,0.1,0.3] + [0.8,0.6,0.7] + [0.9,0.4,0.5] + [0.7,0.5,0.6] + [0.6,0.9,0.8] )}{5}\n",
    "]\n",
    "\n",
    "[\n",
    "V_{avg} = [ (0.2+0.8+0.9+0.7+0.6)/5 , (0.1+0.6+0.4+0.5+0.9)/5 , (0.3+0.7+0.5+0.6+0.8)/5 ]\n",
    "]\n",
    "\n",
    "[\n",
    "V_{avg} = [3.2/5 , 2.5/5 , 2.9/5 ] = [0.64, 0.5, 0.58]\n",
    "]\n",
    "\n",
    "‚úÖ Final Average Word2Vec vector for the sentence = **[0.64, 0.5, 0.58]**\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Python Example (using Gensim)**\n",
    "\n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "sentences = [\n",
    "    [\"i\", \"love\", \"natural\", \"language\", \"processing\"],\n",
    "    [\"word2vec\", \"creates\", \"word\", \"embeddings\"]\n",
    "]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=0)\n",
    "\n",
    "# Function to get average Word2Vec vector for a sentence\n",
    "def get_avg_vector(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Example\n",
    "avg_vec = get_avg_vector([\"i\", \"love\", \"nlp\"], model)\n",
    "print(\"Average Word2Vec vector:\\n\", avg_vec)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Advantages**\n",
    "\n",
    "‚úÖ **Simple and Fast** ‚Äì Easy to compute.\n",
    "‚úÖ **Efficient** ‚Äì Works well for small datasets.\n",
    "‚úÖ **Stable** ‚Äì Reduces noise by averaging.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Disadvantages**\n",
    "\n",
    "‚ùå **Loses Word Order** ‚Äì Sequence of words is ignored.\n",
    "‚ùå **Equal Weighting** ‚Äì All words are treated equally (no importance weighting).\n",
    "‚ùå **Context Ignorance** ‚Äì Does not capture context like BERT or Transformer models.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Applications**\n",
    "\n",
    "* Sentence classification (e.g., spam detection)\n",
    "* Text clustering\n",
    "* Document similarity\n",
    "* Feature extraction for ML models\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Comparison Table**\n",
    "\n",
    "| Technique            | Representation    | Keeps Word Order | Context Aware | Complexity |\n",
    "| -------------------- | ----------------- | ---------------- | ------------- | ---------- |\n",
    "| One-Hot              | Word              | ‚ùå                | ‚ùå             | Low        |\n",
    "| TF-IDF               | Word/Document     | ‚ùå                | ‚ùå             | Medium     |\n",
    "| Word2Vec             | Word              | ‚ùå                | Partially     | Medium     |\n",
    "| **Average Word2Vec** | Sentence/Document | ‚ùå                | ‚ùå             | Medium     |\n",
    "| BERT                 | Sentence          | ‚úÖ                | ‚úÖ             | High       |\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Summary**\n",
    "\n",
    "| Aspect         | Description                                                         |\n",
    "| -------------- | ------------------------------------------------------------------- |\n",
    "| **Definition** | Average of Word2Vec embeddings for all words in a sentence/document |\n",
    "| **Purpose**    | Represent sentence or document as a single vector                   |\n",
    "| **Formula**    | ( V_{avg} = \\frac{1}{n}\\sum_{i=1}^{n}v_i )                          |\n",
    "| **Best For**   | Simple and quick sentence-level representations                     |\n",
    "| **Limitation** | Loses word order and context                                        |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to create this **as a neatly formatted PDF** (with visuals and example code blocks) so you can download and study offline?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99745b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
