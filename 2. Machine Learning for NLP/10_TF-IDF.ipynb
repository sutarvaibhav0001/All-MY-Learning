{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1284f8",
   "metadata": {},
   "source": [
    "Here‚Äôs a **complete, easy-to-understand note on TF-IDF (Term Frequency‚ÄìInverse Document Frequency)** ‚Äî including concept, formula, step-by-step example, and advantages/disadvantages üëá\n",
    "\n",
    "---\n",
    "\n",
    "# üß† TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)\n",
    "\n",
    "## üìò Introduction\n",
    "\n",
    "**TF-IDF** is a statistical measure used in **Natural Language Processing (NLP)** and **Information Retrieval (IR)** to evaluate how important a word is to a document in a collection or corpus.\n",
    "It combines **Term Frequency (TF)** and **Inverse Document Frequency (IDF)** to give a weight to each word.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© 1. Term Frequency (TF)\n",
    "\n",
    "### üîπ Definition\n",
    "\n",
    "TF measures how frequently a term (word) occurs in a document.\n",
    "\n",
    "### üßÆ Formula:\n",
    "\n",
    "[\n",
    "TF(t, d) = \\frac{\\text{Number of times term t appears in document d}}{\\text{Total number of terms in document d}}\n",
    "]\n",
    "\n",
    "### üìñ Example\n",
    "\n",
    "For document D‚ÇÅ:\n",
    "\n",
    "> \"NLP is fun and NLP is powerful\"\n",
    "\n",
    "| Term     | Count | TF (Count / Total words) |\n",
    "| -------- | ----- | ------------------------ |\n",
    "| NLP      | 2     | 2/6 = 0.33               |\n",
    "| is       | 2     | 2/6 = 0.33               |\n",
    "| fun      | 1     | 1/6 = 0.17               |\n",
    "| powerful | 1     | 1/6 = 0.17               |\n",
    "\n",
    "---\n",
    "\n",
    "## üß© 2. Inverse Document Frequency (IDF)\n",
    "\n",
    "### üîπ Definition\n",
    "\n",
    "IDF measures how **important** a term is ‚Äî i.e., how rare or common it is across all documents.\n",
    "A term that appears in **many documents** gets **low weight**, while a rare term gets **high weight**.\n",
    "\n",
    "### üßÆ Formula:\n",
    "\n",
    "[\n",
    "IDF(t) = \\log\\left(\\frac{N}{DF(t)}\\right)\n",
    "]\n",
    "\n",
    "Where:\n",
    "\n",
    "* **N** = total number of documents in the corpus\n",
    "* **DF(t)** = number of documents that contain the term *t*\n",
    "\n",
    "> (Sometimes, to avoid division by zero, we use:\n",
    "> ( IDF(t) = \\log\\left(\\frac{N}{1 + DF(t)}\\right) ))\n",
    "\n",
    "---\n",
    "\n",
    "## üß© 3. TF-IDF Calculation\n",
    "\n",
    "### üîπ Formula:\n",
    "\n",
    "[\n",
    "TF\\text{-}IDF(t, d) = TF(t, d) \\times IDF(t)\n",
    "]\n",
    "\n",
    "### üìä Interpretation:\n",
    "\n",
    "* **High TF-IDF** ‚Üí term is frequent in this document but rare in others ‚Üí important!\n",
    "* **Low TF-IDF** ‚Üí term is common across all documents ‚Üí less useful (e.g., ‚Äúthe‚Äù, ‚Äúis‚Äù).\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Example\n",
    "\n",
    "Let‚Äôs say we have 3 short documents:\n",
    "\n",
    "| Document | Text                               |\n",
    "| -------- | ---------------------------------- |\n",
    "| D‚ÇÅ       | \"NLP is fun\"                       |\n",
    "| D‚ÇÇ       | \"NLP is cool\"                      |\n",
    "| D‚ÇÉ       | \"NLP and machine learning are fun\" |\n",
    "\n",
    "### Step 1Ô∏è‚É£ ‚Äî Vocabulary\n",
    "\n",
    "All unique words:\n",
    "`[\"NLP\", \"is\", \"fun\", \"cool\", \"and\", \"machine\", \"learning\", \"are\"]`\n",
    "\n",
    "### Step 2Ô∏è‚É£ ‚Äî Compute TF for each document\n",
    "\n",
    "| Term     | D‚ÇÅ  | D‚ÇÇ  | D‚ÇÉ  |\n",
    "| -------- | --- | --- | --- |\n",
    "| NLP      | 1/3 | 1/3 | 1/6 |\n",
    "| is       | 1/3 | 1/3 | 0   |\n",
    "| fun      | 1/3 | 0   | 1/6 |\n",
    "| cool     | 0   | 1/3 | 0   |\n",
    "| and      | 0   | 0   | 1/6 |\n",
    "| machine  | 0   | 0   | 1/6 |\n",
    "| learning | 0   | 0   | 1/6 |\n",
    "| are      | 0   | 0   | 1/6 |\n",
    "\n",
    "### Step 3Ô∏è‚É£ ‚Äî Compute IDF\n",
    "\n",
    "| Term     | DF | IDF = log(N/DF) (N=3) |\n",
    "| -------- | -- | --------------------- |\n",
    "| NLP      | 3  | log(3/3)=0            |\n",
    "| is       | 2  | log(3/2)=0.176        |\n",
    "| fun      | 2  | 0.176                 |\n",
    "| cool     | 1  | 0.477                 |\n",
    "| and      | 1  | 0.477                 |\n",
    "| machine  | 1  | 0.477                 |\n",
    "| learning | 1  | 0.477                 |\n",
    "| are      | 1  | 0.477                 |\n",
    "\n",
    "### Step 4Ô∏è‚É£ ‚Äî Compute TF-IDF (TF √ó IDF)\n",
    "\n",
    "| Term     | D‚ÇÅ    | D‚ÇÇ    | D‚ÇÉ    |\n",
    "| -------- | ----- | ----- | ----- |\n",
    "| NLP      | 0     | 0     | 0     |\n",
    "| is       | 0.058 | 0.058 | 0     |\n",
    "| fun      | 0.058 | 0     | 0.029 |\n",
    "| cool     | 0     | 0.159 | 0     |\n",
    "| and      | 0     | 0     | 0.079 |\n",
    "| machine  | 0     | 0     | 0.079 |\n",
    "| learning | 0     | 0     | 0.079 |\n",
    "| are      | 0     | 0     | 0.079 |\n",
    "\n",
    "### üß† Interpretation:\n",
    "\n",
    "* Words like **‚Äúcool‚Äù**, **‚Äúmachine‚Äù**, **‚Äúlearning‚Äù** get **higher TF-IDF** ‚Üí more unique ‚Üí more important.\n",
    "* Common words like **‚ÄúNLP‚Äù**, **‚Äúis‚Äù** get low scores ‚Üí less informative.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Applications of TF-IDF\n",
    "\n",
    "1. **Information Retrieval/Search Engines** ‚Äì rank documents by relevance.\n",
    "2. **Text Classification** ‚Äì convert text into numeric features.\n",
    "3. **Keyword Extraction** ‚Äì identify important terms in a document.\n",
    "4. **Document Similarity** ‚Äì compare texts using cosine similarity of TF-IDF vectors.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Advantages & Disadvantages\n",
    "\n",
    "| ‚úÖ Advantages                             | ‚ùå Disadvantages                                    |\n",
    "| ---------------------------------------- | -------------------------------------------------- |\n",
    "| Simple and effective text representation | Ignores word order (bag-of-words approach)         |\n",
    "| Highlights important/rare terms          | Does not capture semantics (e.g., synonyms)        |\n",
    "| Works well for smaller datasets          | High dimensionality for large vocabularies         |\n",
    "| Used in many ML/NLP tasks                | Static weights ‚Äî not context-aware like embeddings |\n",
    "\n",
    "---\n",
    "\n",
    "## üß∞ Python Example (Using Scikit-learn)\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"NLP is fun\",\n",
    "    \"NLP is cool\",\n",
    "    \"NLP and machine learning are fun\"\n",
    "]\n",
    "\n",
    "# Initialize vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Display feature names and TF-IDF matrix\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "```\n",
    "\n",
    "### üñ•Ô∏è Output (example)\n",
    "\n",
    "```\n",
    "['and' 'are' 'cool' 'fun' 'is' 'learning' 'machine' 'nlp']\n",
    "[[0.   0.   0.   0.707 0.707 0.   0.   0.   ]\n",
    " [0.   0.   0.707 0.   0.707 0.   0.   0.   ]\n",
    " [0.377 0.377 0.   0.377 0.   0.377 0.377 0.377]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Summary\n",
    "\n",
    "| Concept    | Meaning                                             |\n",
    "| ---------- | --------------------------------------------------- |\n",
    "| **TF**     | Frequency of term in document                       |\n",
    "| **IDF**    | Rareness of term across documents                   |\n",
    "| **TF-IDF** | Importance of term (TF √ó IDF)                       |\n",
    "| **Goal**   | Highlight unique, meaningful words in each document |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to **generate a well-formatted PDF** of these TF-IDF notes (with formulas, examples, and tables) for easy study or printing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244696e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
